{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ux-BqlNGRI",
        "outputId": "627d2e43-09f5-4db7-b811-820952c2661b"
      },
      "source": [
        "#connect to drive for getting dataset\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO6EHvnkNeHl",
        "outputId": "63613554-6bbd-47d9-f3fb-505de95dbf28"
      },
      "source": [
        "!pip install pydub\r\n",
        "!pip install librosa\r\n",
        "!pip install flask-ngrok\r\n",
        "!pip install praat-parselmouth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.24.1\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.19.4)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (51.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF_rYQz8sgUI"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.layers import MaxPooling2D,Bidirectional,LSTM,Reshape,BatchNormalization,Flatten,Dropout,Dense,Input,Conv2D, Activation, GlobalAveragePooling2D\r\n",
        "from keras.layers import add\r\n",
        "from keras.utils import plot_model\r\n",
        "import copy\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "import cv2\r\n",
        "import keras\r\n",
        "from keras import backend as K\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.preprocessing.image import load_img, img_to_array\r\n",
        "from keras.applications.resnet50 import preprocess_input, ResNet50\r\n",
        "import keras\r\n",
        "from keras import optimizers\r\n",
        "from keras import backend\r\n",
        "import keras\r\n",
        "from keras import optimizers\r\n",
        "from keras.layers import GaussianNoise\r\n",
        "from keras.regularizers import l2,l1\r\n",
        "\r\n",
        "def resnet_model(size = (256,2048,1)):\r\n",
        "    ''' This model is build using keras module from the paper https://arxiv.org/pdf/1910.12590.pdf\r\n",
        "    inputs are to be resized of 256,2048,1  and the no of classification items. I have fixed to binary as default\r\n",
        "    output is the model\r\n",
        "    '''\r\n",
        "    input  = Input(shape = size)\r\n",
        "    bnEps=2e-5\r\n",
        "    bnMom=0.9\r\n",
        "\r\n",
        "\r\n",
        "    c1 = Conv2D(64, (7,7), padding='same',strides=2, use_bias=False,kernel_initializer='glorot_uniform')(input)\r\n",
        "    b1 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c1)\r\n",
        "\r\n",
        "    c2 = conv1 = Conv2D(32, (3,3),strides=2, padding='same', use_bias=False,kernel_initializer='glorot_uniform')(input)\r\n",
        "    b2 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c2)\r\n",
        "    a2 = Activation('relu')(b2)\r\n",
        "\r\n",
        "    c3 = conv1 = Conv2D(64, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a2)\r\n",
        "    b3 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c3)\r\n",
        "    a3 = Activation('relu')(b3)\r\n",
        "\r\n",
        "    c4 = conv1 = Conv2D(64, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a3)\r\n",
        "    b4 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c4)\r\n",
        "\r\n",
        "    m1  = add([c1, b4])\r\n",
        "    m1 = GaussianNoise(0.1)(m1)\r\n",
        "    a4 = Activation('relu')(m1)\r\n",
        "\r\n",
        "\r\n",
        "    #-----------------------------------------------layer 2----------------------------------------------------------------------------\r\n",
        "\r\n",
        "    c1 = Conv2D(128, (3,3),strides=2, padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b1 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c1)\r\n",
        "\r\n",
        "    c2 = conv1 = Conv2D(64, (3,3),strides=2, padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b2 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c2)\r\n",
        "    a2 = Activation('relu')(b2)\r\n",
        "\r\n",
        "    c3 = conv1 = Conv2D(128, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a2)\r\n",
        "    b3 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c3)\r\n",
        "    a3 = Activation('relu')(b3)\r\n",
        "\r\n",
        "    c4 = conv1 = Conv2D(128, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a3)\r\n",
        "    b4 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c4)\r\n",
        "\r\n",
        "    m1  = add([c1, b4])\r\n",
        "    m1 = GaussianNoise(0.1)(m1)\r\n",
        "\r\n",
        "    a4 = Activation('relu')(m1)\r\n",
        "\r\n",
        "    #----------------------------------------------layer 3------------------------------------------------------------------------------\r\n",
        "\r\n",
        "    c1 = Conv2D(128, (3,3),strides = (1,2) ,padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b1 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c1)\r\n",
        "\r\n",
        "    c2 = conv1 = Conv2D(128, (3,3),strides = (1,2), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b2 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c2)\r\n",
        "    a2 = Activation('relu')(b2)\r\n",
        "\r\n",
        "    c3 = conv1 = Conv2D(128, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a2)\r\n",
        "    b3 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c3)\r\n",
        "    a3 = Activation('relu')(b3)\r\n",
        "\r\n",
        "\r\n",
        "    c4 = conv1 = Conv2D(128, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a3)\r\n",
        "    b4 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c4)\r\n",
        "\r\n",
        "    m1  = add([c1, b4])\r\n",
        "    m1 = GaussianNoise(0.1)(m1)\r\n",
        "\r\n",
        "    a4 = Activation('relu')(m1)\r\n",
        "\r\n",
        "    #-------------------------------------------layer 4---------------------------------------------------------------------------------\r\n",
        "\r\n",
        "    c1 = Conv2D(64, (3,3),strides = (2,2) ,padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b1 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c1)\r\n",
        "\r\n",
        "    c2 = conv1 = Conv2D(128, (3,3),strides = (2,2), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b2 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c2)\r\n",
        "    a2 = Activation('relu')(b2)\r\n",
        "\r\n",
        "    c3 = conv1 = Conv2D(64, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a2)\r\n",
        "    b3 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c3)\r\n",
        "    a3 = Activation('relu')(b3)\r\n",
        "\r\n",
        "\r\n",
        "    c4 = conv1 = Conv2D(64, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a3)\r\n",
        "    b4 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c4)\r\n",
        "\r\n",
        "    m1  = add([c1, b4])\r\n",
        "    m1 = GaussianNoise(0.1)(m1)\r\n",
        "\r\n",
        "    a4 = Activation('relu')(m1)\r\n",
        "\r\n",
        "    #-------------------------------------------layer 5-----------------------------------------------------------------------------------\r\n",
        "    c1 = Conv2D(32, (3,3),strides = (2,2) ,padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b1 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c1)\r\n",
        "\r\n",
        "    c2 = conv1 = Conv2D(64, (3,3),strides = (2,2), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b2 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c2)\r\n",
        "    a2 = Activation('relu')(b2)\r\n",
        "\r\n",
        "    c3 = conv1 = Conv2D(64, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a2)\r\n",
        "    b3 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c3)\r\n",
        "    a3 = Activation('relu')(b3)\r\n",
        "\r\n",
        "\r\n",
        "    c4 = conv1 = Conv2D(32, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a3)\r\n",
        "    b4 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c4)\r\n",
        "\r\n",
        "    m1  = add([c1, b4])\r\n",
        "    m1 = GaussianNoise(0.1)(m1)\r\n",
        "    a4 = Activation('relu')(m1)\r\n",
        "\r\n",
        "    #-----------------------------------------layer 6-------------------------------------------------------------------------\r\n",
        "    c1 = Conv2D(16, (3,3),strides = (2,2) ,padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b1 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c1)\r\n",
        "\r\n",
        "    c2 = conv1 = Conv2D(32, (3,3),strides = (2,2), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a4)\r\n",
        "    b2 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c2)\r\n",
        "    a2 = Activation('relu')(b2)\r\n",
        "\r\n",
        "    c3 = conv1 = Conv2D(32, (3,3), padding='same', use_bias=False,kernel_initializer='glorot_uniform')(a2)\r\n",
        "    b3 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c3)\r\n",
        "    a3 = Activation('relu')(b3)\r\n",
        "\r\n",
        "\r\n",
        "    c4 = conv1 = Conv2D(16, (3,3), padding='same',use_bias=False,kernel_initializer='glorot_uniform')(a3)\r\n",
        "    b4 = BatchNormalization(epsilon=bnEps, momentum=bnMom)(c4)\r\n",
        "\r\n",
        "    m1  = add([c1, b4])\r\n",
        "    m1 = GaussianNoise(0.1)(m1)\r\n",
        "    a4 = Activation('relu')(m1)\r\n",
        "\r\n",
        "    f = Flatten()(a4)\r\n",
        "    # f = Reshape((int(8192/2), 1))(f)\r\n",
        "\r\n",
        "    # #-----------------------------------------layer7---------------------------------------------------------------------------\r\n",
        "    # bi1 = Bidirectional(LSTM(512, return_sequences=True))(f)\r\n",
        "    bi1 = Dense(1024,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),activity_regularizer=l1(0.0001))(f)\r\n",
        "    d1  = Dropout(0.2)(bi1)\r\n",
        "    n1 = GaussianNoise(0.1)(d1)\r\n",
        "    # model.add()\r\n",
        "\r\n",
        "    # bi2 = Bidirectional(LSTM(512))(d1)\r\n",
        "    bi2 = Dense(512,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01),activity_regularizer=l1(0.0001))(n1)\r\n",
        "    d2 = Dropout(0.4)(bi2)\r\n",
        "    n1 = GaussianNoise(0.1)(d2)\r\n",
        "\r\n",
        "    out = Dense(2,activation='sigmoid')(n1)\r\n",
        "\r\n",
        "    # create model\r\n",
        "    model = Model(inputs=input, outputs=out)\r\n",
        "    return model\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ7NJLZiwPxN"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import librosa\r\n",
        "from pydub import AudioSegment\r\n",
        "from tqdm import tqdm\r\n",
        "from glob import glob\r\n",
        "   \r\n",
        "def clean_complete_dir(path_to_folder):\r\n",
        "\r\n",
        "  if not os.path.exists(path_to_folder):\r\n",
        "    os.makedirs(path_to_folder)\r\n",
        "\r\n",
        "  print('started cleaning directory'.center(100,'-'))\r\n",
        "  files = glob(path_to_folder+'/*')\r\n",
        "  for f in files:\r\n",
        "      os.remove(f)\r\n",
        "  print('directory cleanining done'.center(100,'-'))\r\n",
        "\r\n",
        "\r\n",
        "def chunk(wav,t1,t2,newf):\r\n",
        "    t1 = t1 * 1000 #Works in milliseconds\r\n",
        "    t2 = t2 * 1000\r\n",
        "    newAudio = AudioSegment.from_wav(wav)\r\n",
        "    newAudio = newAudio[t1:t2]\r\n",
        "    newAudio.export(newf, format=\"wav\")\r\n",
        "\r\n",
        "def make_chunks(audio_file):\r\n",
        "\r\n",
        "  clean_complete_dir('/content/chunked_audio_files')\r\n",
        "\r\n",
        "\r\n",
        "  print('initiated making chunks'.center(100,'-'))\r\n",
        "  y,sr = librosa.load(audio_file,sr = 41000)\r\n",
        "  time_duration = librosa.get_duration(y,sr)\r\n",
        "  timing_chunks = np.arange(0,int(time_duration),10)\r\n",
        "\r\n",
        "  print(f'the number of chunks are {len(timing_chunks)}'.center(100,'-'))\r\n",
        "\r\n",
        "  for i in range(len(timing_chunks[:-1])):\r\n",
        "    chunk(audio_file,timing_chunks[i],timing_chunks[i+1],f'/content/chunked_audio_files/{i}.wav')\r\n",
        "\r\n",
        "  print('making data is done'.center(100,'-'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjGAKNhcxyl7",
        "outputId": "301f9bd5-2267-4ba8-d4fd-deffefc31bbe"
      },
      "source": [
        "make_chunks('/content/drive/MyDrive/mini_project_2/97.wav')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "--------------------------------------initiated making chunks---------------------------------------\n",
            "------------------------------------the number of chunks are 13-------------------------------------\n",
            "----------------------------------------making data is done-----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3mji2FE1rAV"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import matplotlib\r\n",
        "import pylab\r\n",
        "import librosa\r\n",
        "import librosa.display\r\n",
        "import numpy as np\r\n",
        "from pydub import AudioSegment\r\n",
        "from pydub.utils import make_chunks\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import matplotlib \r\n",
        "from glob import glob\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFH-3yYa17AP"
      },
      "source": [
        "def mel_spectrogram(audio_path,save_path,max_frequency):\r\n",
        "    '''\r\n",
        "    inputs self,save_path,frequency limits,save\r\n",
        "    saves a image as output\r\n",
        "    '''\r\n",
        "    plt.figure(figsize=(14, 5))\r\n",
        "    signal,sr = librosa.load(audio_path,sr = 22050)\r\n",
        "    pre_emphasis = 0.97\r\n",
        "    y = np.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\r\n",
        "    \r\n",
        "\r\n",
        "    melSpec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\r\n",
        "    melSpec_dB = librosa.power_to_db(melSpec, ref=np.max)\r\n",
        "\r\n",
        "    pylab.axis('off') # no axis\r\n",
        "    pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[]) # Remove the white edge\r\n",
        "\r\n",
        "    librosa.display.specshow(melSpec_dB, x_axis='time', y_axis='mel', sr=sr, fmax=max_frequency)\r\n",
        "\r\n",
        "    pylab.savefig(save_path, bbox_inches=None, pad_inches=0)\r\n",
        "    pylab.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U36WRV4x1_fs"
      },
      "source": [
        "def make_spectrogram(chunked_audio_files):\r\n",
        "    data = sorted(glob(f'{chunked_audio_files}/*.wav'))\r\n",
        "\r\n",
        "    clean_complete_dir('/content/spectrograms')\r\n",
        "\r\n",
        "    for no,file in enumerate(data):\r\n",
        "        name = str(no)+'.png'\r\n",
        "        mel_spectrogram(file,'/content/spectrograms/'+name,5000)\r\n",
        "    \r\n",
        "    print(\"making of spectrograms is done\".center(100,'-'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuJbsI832CLP",
        "outputId": "88b0f988-d84a-4d33-a595-3f66832cd57a"
      },
      "source": [
        "path = '/content/chunked_audio_files'\r\n",
        "make_spectrogram(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-----------------------------------making of spectrograms is done-----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5_ZqH7asti_"
      },
      "source": [
        "model = resnet_model()\r\n",
        "model_path = '/content/drive/MyDrive/mini_project_2/weight_reg-model.04-0.30.h5'\r\n",
        "model.load_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyl756UDPIH6",
        "outputId": "177d7526-5501-448e-cfc5-8e9b26d2d490"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting praat-parselmouth\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7b/9fa1172a63b6277603d27bb5613559b5a8888f58e68c1698017b87b0061d/praat_parselmouth-0.3.3-cp36-cp36m-manylinux1_x86_64.whl (9.0MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0MB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from praat-parselmouth) (1.19.4)\n",
            "Installing collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCFQPMQ6PGzo"
      },
      "source": [
        "import parselmouth\r\n",
        "import time\r\n",
        "from tqdm import tqdm\r\n",
        "from glob import glob\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import librosa\r\n",
        "from pydub import AudioSegment\r\n",
        "from tqdm import tqdm\r\n",
        "from glob import glob\r\n",
        "import plotly.graph_objects as go\r\n",
        "from shutil import copyfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQtjSDXMNxrZ"
      },
      "source": [
        "def praat_script(i):\r\n",
        "  clean_complete_dir('/content/rough')\r\n",
        "  # all_files = glob('/content/chunked_audio_files/*.wav')\r\n",
        "  # for i in tqdm(all_files):\r\n",
        "  name = i.split('/')[-1]\r\n",
        "  dst = 'rough/'+name\r\n",
        "  copyfile(i, dst)\r\n",
        "  path = '/content/rough'\r\n",
        "\r\n",
        "  try:\r\n",
        "        objects, output = parselmouth.praat.run_file('/content/nucleus.praat',-25,2,0.3,'yes',path, capture_output=True)\r\n",
        "        outputs = output.split('\\n')[1:]\r\n",
        "        outputs = outputs[0].split(',')\r\n",
        "        return float(outputs[4])\r\n",
        "\r\n",
        "  except:\r\n",
        "        print('error occured at',i)\r\n",
        "        return False\r\n",
        "       \r\n",
        "  clean_complete_dir('/content/rough')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gxpvHDhtD66",
        "outputId": "7489ec55-bf7a-41dc-d80a-9b4410fa893f"
      },
      "source": [
        "spectrograms_path = '/content/spectrograms/'\r\n",
        "\r\n",
        "def make_prediction(image_path):\r\n",
        "    img = cv2.imread(image_path,0)/255.0\r\n",
        "    img = cv2.resize(img,(2048,256))\r\n",
        "    img = np.expand_dims(img,0)\r\n",
        "    result = model.predict(img)\r\n",
        "    return result\r\n",
        "\r\n",
        "data = []\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def threshold(value):\r\n",
        "  if value > 0.7:\r\n",
        "    return 'True'\r\n",
        "  else:\r\n",
        "    return 'False'\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def making_results(img_file,wav_file):\r\n",
        "\r\n",
        "    filler = 'False'\r\n",
        "    repetition = 'False'\r\n",
        "    long_pause = 'False'\r\n",
        "\r\n",
        "    praat_output = praat_script(wav_file)\r\n",
        "\r\n",
        "    if praat_output > 1.0:\r\n",
        "      result = make_prediction(img_file)\r\n",
        "      result = result.flatten()\r\n",
        "      filler,repetition = threshold(result[0]),threshold(result[1])\r\n",
        "      filler = filler +'--'+ str(round(result[0],3))\r\n",
        "      repetition = repetition+'--' + str(round(result[1],3))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    if praat_output < 2.0:\r\n",
        "      long_pause = 'True'+'--'+str(praat_output)\r\n",
        "\r\n",
        "    return ([wav_file.split('/')[-1], filler, repetition , long_pause])\r\n",
        "\r\n",
        "\r\n",
        "data = []\r\n",
        "\r\n",
        "for img_file,wav_file in zip(sorted(glob(spectrograms_path+'*.png')),sorted(glob('/content/chunked_audio_files/'+'*'))):\r\n",
        "\r\n",
        "    data.append(making_results(img_file,wav_file))\r\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "-------------------------------------started cleaning directory-------------------------------------\n",
            "-------------------------------------directory cleanining done--------------------------------------\n",
            "[['0.wav', 'False--0.016', 'False--0.039', 'False'], ['1.wav', 'False--0.031', 'False--0.005', 'False'], ['10.wav', 'False--0.163', 'False--0.12', 'False'], ['11.wav', 'False--0.297', 'False--0.011', 'False'], ['2.wav', 'False--0.017', 'False--0.062', 'False'], ['3.wav', 'False--0.021', 'False--0.073', 'False'], ['4.wav', 'False--0.029', 'False--0.014', 'False'], ['5.wav', 'False--0.018', 'False--0.136', 'False'], ['6.wav', 'False--0.051', 'False--0.007', 'False'], ['7.wav', 'False--0.019', 'False--0.057', 'False'], ['8.wav', 'False--0.251', 'False--0.018', 'False'], ['9.wav', 'False--0.036', 'False--0.047', 'False']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIel9aWW-ayf",
        "outputId": "dc86827b-15ad-4ad9-f404-d6027728e3e3"
      },
      "source": [
        "from flask import Flask, render_template\r\n",
        "from flask import request\r\n",
        "from flask_ngrok import run_with_ngrok\r\n",
        "\r\n",
        "app = Flask(__name__,template_folder='/content/',static_folder = '/content/chunked_audio_files')\r\n",
        "\r\n",
        "run_with_ngrok(app)  # Start ngrok when app is run\r\n",
        "\r\n",
        "@app.route(\"/\")\r\n",
        "def root():\r\n",
        "    # url = request.method\r\n",
        "    return render_template(\"index.html\", len = len(data), data = data)\r\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://b76bb1aad82e.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [31/Dec/2020 01:22:15] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:16] \"\u001b[37mGET /chunked_audio_files/0.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:16] \"\u001b[37mGET /chunked_audio_files/10.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:16] \"\u001b[37mGET /chunked_audio_files/1.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:16] \"\u001b[37mGET /chunked_audio_files/11.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:16] \"\u001b[37mGET /chunked_audio_files/2.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:16] \"\u001b[37mGET /chunked_audio_files/3.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:18] \"\u001b[37mGET /chunked_audio_files/4.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:18] \"\u001b[37mGET /chunked_audio_files/5.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:18] \"\u001b[37mGET /chunked_audio_files/6.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:18] \"\u001b[37mGET /chunked_audio_files/8.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:18] \"\u001b[37mGET /chunked_audio_files/7.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:18] \"\u001b[37mGET /chunked_audio_files/9.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:20] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:23] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:24] \"\u001b[37mGET /chunked_audio_files/6.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:22:34] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:23:30] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:23:31] \"\u001b[37mGET /chunked_audio_files/0.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:23:31] \"\u001b[37mGET /chunked_audio_files/1.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:23:31] \"\u001b[37mGET /chunked_audio_files/10.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:23:44] \"\u001b[37mGET /chunked_audio_files/8.wav HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [31/Dec/2020 01:23:44] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDyIGWUE87s4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}